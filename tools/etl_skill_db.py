#!/usr/bin/env python3
"""
ETL: è¦‡é“DB.xlsx â†’ data-skill-db.js
æŠ€èƒ½DBã‚·ãƒ¼ãƒˆï¼ˆPower Queryçµ±åˆãƒ“ãƒ¥ãƒ¼ï¼‰ã‚’èª­ã¿è¾¼ã¿ã€
SKILL_DB ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’JSãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã™ã‚‹ã€‚

ä½¿ã„æ–¹:
  python etl_skill_db.py è¦‡é“DB.xlsx data-skill-db.js

èª­è¾¼ä»•æ§˜:
  - è¡Œ1: æƒ…å ±è¡Œï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰
  - è¡Œ2: ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ39åˆ—ï¼‰
  - è¡Œ3ã€œ: ãƒ‡ãƒ¼ã‚¿ï¼ˆ5,733è¡Œï¼‰
"""

import sys
import json
import unicodedata
from collections import defaultdict
from openpyxl import load_workbook

# === å®šæ•° ===

# å…±é€šåˆ—ã®åˆ—ç•ªå·ï¼ˆ1-indexedï¼‰
COL_MAP = {
    'ID': 1,
    'å®Ÿè£…æ—¥': 2,
    'æ›´æ–°æ—¥æ™‚': 3,
    'åç§°': 4,
    'ï¾šï½±': 5,
    'é–¢é€£': 6,
    'ç¨®é¡1': 7,
    'ç¨®é¡2': 8,
    'åŠ¹æœ': 9,
    'åŠ¹æœx': 10,
    'ç™ºå‹•æ¡ä»¶': 11,
    'ç™ºå‹•æ¡ä»¶2': 12,
    'ç™ºå‹•ã‚¿ã‚¤ãƒŸãƒ³ã‚°': 13,
    'è¿½åŠ åŠ¹æœ': 14,
    'ç¢ºç‡': 15,
    'å¯¾è±¡éƒ¨éšŠæ•°': 16,
    'åŠ¹æœæ™‚é–“': 17,
    'åŠ¹æœé‡': 18,
    # â… ã€œâ…©: 19ã€œ28
    'èª¬æ˜æ–‡': 29,
    # åˆ†æ9åˆ—: 30ã€œ38ï¼ˆ39åˆ—ã‚·ãƒ¼ãƒˆï¼‰or 30ã€œ38ï¼ˆ38åˆ—ã‚·ãƒ¼ãƒˆï¼‰
}

LEVEL_COLS = {
    'â… ': 19, 'â…¡': 20, 'â…¢': 21, 'â…£': 22, 'â…¤': 23,
    'â…¥': 24, 'â…¦': 25, 'â…§': 26, 'â…¨': 27, 'â…©': 28,
}

# åˆ†æ9åˆ—ï¼ˆ39åˆ—ã‚·ãƒ¼ãƒˆã®å ´åˆ: åˆ—30-38ã€Name=åˆ—39ï¼‰
ANALYSIS_COLS_39 = {
    'åŠ¹æœNo': 30, 'å€¤ç¨®åˆ¥': 31, 'ä¹—ç®—å¤‰æ•°': 32, 'ä¹—ç®—å¯¾è±¡': 33,
    'è¿½åŠ æ¡ä»¶': 34, 'æ¡ä»¶å€ç‡': 35, 'ä¸Šé™å€¤': 36, 'ç™ºå‹•å›æ•°': 37, 'æ”»æ’ƒç³»çµ±': 38,
}
# Nameåˆ—: 39åˆ—ã‚·ãƒ¼ãƒˆâ†’åˆ—39ã€38åˆ—ã‚·ãƒ¼ãƒˆâ†’ãªã—


def nfkc(val):
    """Unicode NFKCæ­£è¦åŒ–"""
    if isinstance(val, str):
        return unicodedata.normalize('NFKC', val).strip()
    return val


def safe_str(val):
    """ã‚»ãƒ«å€¤ã‚’å®‰å…¨ã«æ–‡å­—åˆ—åŒ–"""
    if val is None:
        return None
    if isinstance(val, (int, float)):
        return str(val) if val != 0 else None
    s = nfkc(str(val))
    return s if s else None


def safe_num(val):
    """ã‚»ãƒ«å€¤ã‚’å®‰å…¨ã«æ•°å€¤åŒ–"""
    if val is None:
        return None
    if isinstance(val, (int, float)):
        return val
    try:
        return float(nfkc(str(val)))
    except (ValueError, TypeError):
        return None


def read_skill_db_sheet(wb, sheet_name='æŠ€èƒ½DB'):
    """æŠ€èƒ½DBã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    ws = wb[sheet_name]
    rows = list(ws.iter_rows(min_row=3, values_only=True))  # è¡Œ3ã€œï¼ˆè¡Œ1=æƒ…å ±è¡Œ, è¡Œ2=ãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰

    # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèªï¼ˆè¡Œ2ï¼‰
    header_row = list(ws.iter_rows(min_row=2, max_row=2, values_only=True))[0]
    total_cols = len([c for c in header_row if c is not None])
    has_name_col = total_cols >= 39

    skills = defaultdict(lambda: {'id': None, 'effects': [], 'owners': [], 'source': None})
    seen_names = set()

    for row_idx, row in enumerate(rows):
        if not row or len(row) < 18:
            continue

        skill_name = safe_str(row[COL_MAP['åç§°'] - 1])
        if not skill_name:
            continue

        skill_id = safe_num(row[COL_MAP['ID'] - 1])
        type2 = safe_str(row[COL_MAP['ç¨®é¡2'] - 1])

        # Nameã®ä½ç½®ï¼ˆ39åˆ—â†’åˆ—39ã€38åˆ—â†’ãªã—ï¼‰
        source = None
        if has_name_col and len(row) >= 39:
            source = safe_str(row[38])  # 0-indexed: åˆ—39â†’index 38

        entry = skills[skill_name]
        if entry['id'] is None and skill_id is not None:
            entry['id'] = int(skill_id)
        if source and not entry['source']:
            entry['source'] = source

        # æ‰€æŒè¡Œã®å‡¦ç†
        if type2 == 'æ‰€æŒ':
            rarity = safe_str(row[COL_MAP['ï¾šï½±'] - 1])
            related = safe_str(row[COL_MAP['é–¢é€£'] - 1])
            if related:
                entry['owners'].append({'name': related, 'rarity': rarity or ''})
            continue

        # åŠ¹æœè¡Œã®å‡¦ç†
        effect = {
            'effectNo': safe_num(row[ANALYSIS_COLS_39['åŠ¹æœNo'] - 1]) if len(row) >= 30 else None,
            'type1': safe_str(row[COL_MAP['ç¨®é¡1'] - 1]),
            'type2': type2,
            'effect': safe_str(row[COL_MAP['åŠ¹æœ'] - 1]),
            'effectX': safe_str(row[COL_MAP['åŠ¹æœx'] - 1]),
            'condition': safe_str(row[COL_MAP['ç™ºå‹•æ¡ä»¶'] - 1]),
            'condition2': safe_str(row[COL_MAP['ç™ºå‹•æ¡ä»¶2'] - 1]),
            'timing': safe_str(row[COL_MAP['ç™ºå‹•ã‚¿ã‚¤ãƒŸãƒ³ã‚°'] - 1]),
            'extra': safe_str(row[COL_MAP['è¿½åŠ åŠ¹æœ'] - 1]),
            'probability': safe_str(row[COL_MAP['ç¢ºç‡'] - 1]),
            'targetCount': safe_str(row[COL_MAP['å¯¾è±¡éƒ¨éšŠæ•°'] - 1]),
            'duration': safe_str(row[COL_MAP['åŠ¹æœæ™‚é–“'] - 1]),
            'amount': safe_str(row[COL_MAP['åŠ¹æœé‡'] - 1]),
            'levels': {},
            'description': safe_str(row[COL_MAP['èª¬æ˜æ–‡'] - 1]),
        }

        # â… ã€œâ…© ã®ãƒ¬ãƒ™ãƒ«å€¤
        for lv_name, col in LEVEL_COLS.items():
            val = safe_num(row[col - 1]) if len(row) >= col else None
            if val is not None:
                effect['levels'][lv_name] = val

        # åˆ†æ9åˆ—
        if len(row) >= 38:
            effect['valueType'] = safe_str(row[ANALYSIS_COLS_39['å€¤ç¨®åˆ¥'] - 1])
            effect['multiVar'] = safe_str(row[ANALYSIS_COLS_39['ä¹—ç®—å¤‰æ•°'] - 1])
            effect['multiTarget'] = safe_str(row[ANALYSIS_COLS_39['ä¹—ç®—å¯¾è±¡'] - 1])
            effect['extraCondition'] = safe_str(row[ANALYSIS_COLS_39['è¿½åŠ æ¡ä»¶'] - 1])
            effect['conditionRate'] = safe_num(row[ANALYSIS_COLS_39['æ¡ä»¶å€ç‡'] - 1])
            effect['capValue'] = safe_num(row[ANALYSIS_COLS_39['ä¸Šé™å€¤'] - 1])
            effect['activationCount'] = safe_num(row[ANALYSIS_COLS_39['ç™ºå‹•å›æ•°'] - 1])
            effect['attackType'] = safe_str(row[ANALYSIS_COLS_39['æ”»æ’ƒç³»çµ±'] - 1])

        # effectNoãŒintã®å ´åˆã¯æ•´æ•°åŒ–
        if effect['effectNo'] is not None:
            effect['effectNo'] = int(effect['effectNo'])
        if effect['conditionRate'] is not None and effect['conditionRate'] == int(effect['conditionRate']):
            effect['conditionRate'] = int(effect['conditionRate'])
        if effect['activationCount'] is not None and effect['activationCount'] == int(effect['activationCount']):
            effect['activationCount'] = int(effect['activationCount'])

        entry['effects'].append(effect)

    return dict(skills)


def write_js(skills, output_path):
    """SKILL_DB ã‚’ JSãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™"""

    def clean_none(obj):
        """Noneå€¤ã‚’nullã«ã€ç©ºdictã‚’é™¤å»"""
        if isinstance(obj, dict):
            return {k: clean_none(v) for k, v in obj.items() if v is not None}
        if isinstance(obj, list):
            return [clean_none(v) for v in obj]
        return obj

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('// data-skill-db.js â€” æŠ€èƒ½DBå…¨é‡ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰\n')
        f.write('// ç”Ÿæˆå…ƒ: è¦‡é“DB.xlsx æŠ€èƒ½DBã‚·ãƒ¼ãƒˆ\n')
        f.write(f'// æŠ€èƒ½æ•°: {len(skills)}\n')

        total_effects = sum(len(v['effects']) for v in skills.values())
        f.write(f'// åŠ¹æœè¡Œ: {total_effects}\n\n')
        f.write('const SKILL_DB = ')

        # JSONå¤‰æ›ï¼ˆèª­ã¿ã‚„ã™ã„ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆï¼‰
        cleaned = {}
        for name, data in skills.items():
            cleaned[name] = clean_none(data)

        json_str = json.dumps(cleaned, ensure_ascii=False, indent=2)
        f.write(json_str)
        f.write(';\n')

    print(f'âœ… {output_path} ç”Ÿæˆå®Œäº†')
    print(f'   æŠ€èƒ½æ•°: {len(skills)}')
    print(f'   åŠ¹æœè¡Œ: {total_effects}')


def main():
    if len(sys.argv) < 3:
        print('ä½¿ã„æ–¹: python etl_skill_db.py <è¦‡é“DB.xlsx> <å‡ºåŠ›å…ˆ.js>')
        sys.exit(1)

    input_path = sys.argv[1]
    output_path = sys.argv[2]

    print(f'ğŸ“– èª­è¾¼ä¸­: {input_path}')
    wb = load_workbook(input_path, read_only=True, data_only=True)

    if 'æŠ€èƒ½DB' not in wb.sheetnames:
        print('âŒ æŠ€èƒ½DB ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        sys.exit(1)

    skills = read_skill_db_sheet(wb)
    wb.close()

    write_js(skills, output_path)


if __name__ == '__main__':
    main()
